{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7498956,"sourceType":"datasetVersion","datasetId":4366670}],"dockerImageVersionId":30635,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-29T20:01:31.278163Z","iopub.execute_input":"2024-01-29T20:01:31.278509Z","iopub.status.idle":"2024-01-29T20:01:32.346090Z","shell.execute_reply.started":"2024-01-29T20:01:31.278459Z","shell.execute_reply":"2024-01-29T20:01:32.345143Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/fresult/result.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"root = '/kaggle/working/'\noutput_dir = os.path.join(root, \"outputs\")\nnew_model_path = os.path.join(root, \"model\")\ndata_dir = os.path.join(root, \"data\")\ntrain_path = os.path.join(data_dir, \"train.csv\")\ntest_path = os.path.join(data_dir, \"test.csv\")\n\nos.makedirs(new_model_path, exist_ok=True)\nos.makedirs(output_dir, exist_ok=True)\nos.makedirs(data_dir, exist_ok=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-29T20:01:32.348180Z","iopub.execute_input":"2024-01-29T20:01:32.348722Z","iopub.status.idle":"2024-01-29T20:01:32.355958Z","shell.execute_reply.started":"2024-01-29T20:01:32.348685Z","shell.execute_reply":"2024-01-29T20:01:32.354904Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"!pip install datasets peft trl","metadata":{"execution":{"iopub.status.busy":"2024-01-29T20:01:32.357071Z","iopub.execute_input":"2024-01-29T20:01:32.357366Z","iopub.status.idle":"2024-01-29T20:01:47.996959Z","shell.execute_reply.started":"2024-01-29T20:01:32.357340Z","shell.execute_reply":"2024-01-29T20:01:47.995707Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\nCollecting peft\n  Obtaining dependency information for peft from https://files.pythonhosted.org/packages/8b/1b/aee2a330d050c493642d59ba6af51f3910cb138ea48ede228c84c204a5af/peft-0.7.1-py3-none-any.whl.metadata\n  Downloading peft-0.7.1-py3-none-any.whl.metadata (25 kB)\nCollecting trl\n  Obtaining dependency information for trl from https://files.pythonhosted.org/packages/61/ae/fb06164af1d535947067492f6db43446d984d1bfa7084f88dcae12ae7b48/trl-0.7.10-py3-none-any.whl.metadata\n  Downloading trl-0.7.10-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.24.3)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.0.3)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.15)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2023.12.2)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.8.5)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.20.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.18.0)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.1)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.0.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.36.2)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.25.0)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.1)\nCollecting tyro>=0.5.11 (from trl)\n  Obtaining dependency information for tyro>=0.5.11 from https://files.pythonhosted.org/packages/b5/d2/0f8812ddc01f602f31489f1141f13100eef7b24f00a14b2fd27d9e8cbc97/tyro-0.7.0-py3-none-any.whl.metadata\n  Downloading tyro-0.7.0-py3-none-any.whl.metadata (7.7 kB)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (3.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.12.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.11.17)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2023.8.8)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.15.0)\nRequirement already satisfied: docstring-parser>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl) (0.15)\nRequirement already satisfied: rich>=11.1.0 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl) (13.5.2)\nCollecting shtab>=1.5.6 (from tyro>=0.5.11->trl)\n  Obtaining dependency information for shtab>=1.5.6 from https://files.pythonhosted.org/packages/40/ad/7227da64498eaa7abecee4311008f70869e156014b3270cec36e2e70cd31/shtab-1.6.5-py3-none-any.whl.metadata\n  Downloading shtab-1.6.5-py3-none-any.whl.metadata (7.3 kB)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.16.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\nDownloading peft-0.7.1-py3-none-any.whl (168 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.3/168.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading trl-0.7.10-py3-none-any.whl (150 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.9/150.9 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tyro-0.7.0-py3-none-any.whl (79 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.7/79.7 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading shtab-1.6.5-py3-none-any.whl (13 kB)\nInstalling collected packages: shtab, tyro, trl, peft\nSuccessfully installed peft-0.7.1 shtab-1.6.5 trl-0.7.10 tyro-0.7.0\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install --upgrade datasets","metadata":{"execution":{"iopub.status.busy":"2024-01-29T20:01:47.999428Z","iopub.execute_input":"2024-01-29T20:01:47.999766Z","iopub.status.idle":"2024-01-29T20:02:03.001560Z","shell.execute_reply.started":"2024-01-29T20:01:47.999735Z","shell.execute_reply":"2024-01-29T20:02:03.000349Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\nCollecting datasets\n  Obtaining dependency information for datasets from https://files.pythonhosted.org/packages/ec/93/454ada0d1b289a0f4a86ac88dbdeab54921becabac45da3da787d136628f/datasets-2.16.1-py3-none-any.whl.metadata\n  Downloading datasets-2.16.1-py3-none-any.whl.metadata (20 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.12.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.24.3)\nRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\nCollecting pyarrow-hotfix (from datasets)\n  Obtaining dependency information for pyarrow-hotfix from https://files.pythonhosted.org/packages/e4/f4/9ec2222f5f5f8ea04f66f184caafd991a39c8782e31f5b0266f101cb68ca/pyarrow_hotfix-0.6-py3-none-any.whl.metadata\n  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\nRequirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.0.3)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.15)\nCollecting fsspec[http]<=2023.10.0,>=2023.1.0 (from datasets)\n  Obtaining dependency information for fsspec[http]<=2023.10.0,>=2023.1.0 from https://files.pythonhosted.org/packages/e8/f6/3eccfb530aac90ad1301c582da228e4763f19e719ac8200752a4841b0b2d/fsspec-2023.10.0-py3-none-any.whl.metadata\n  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.8.5)\nRequirement already satisfied: huggingface-hub>=0.19.4 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.20.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (3.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->datasets) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.11.17)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nDownloading datasets-2.16.1-py3-none-any.whl (507 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\nDownloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: pyarrow-hotfix, fsspec, datasets\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2023.12.2\n    Uninstalling fsspec-2023.12.2:\n      Successfully uninstalled fsspec-2023.12.2\n  Attempting uninstall: datasets\n    Found existing installation: datasets 2.1.0\n    Uninstalling datasets-2.1.0:\n      Successfully uninstalled datasets-2.1.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.1 which is incompatible.\ncuml 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.1 which is incompatible.\ndask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.1 which is incompatible.\ndask-cuda 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.1 which is incompatible.\ndask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.1 which is incompatible.\ndask-cudf 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.1 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\ngcsfs 2023.6.0 requires fsspec==2023.6.0, but you have fsspec 2023.10.0 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.1 which is incompatible.\nraft-dask 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.1 which is incompatible.\ns3fs 2023.12.2 requires fsspec==2023.12.2, but you have fsspec 2023.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed datasets-2.16.1 fsspec-2023.10.0 pyarrow-hotfix-0.6\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install bitsandbytes","metadata":{"execution":{"iopub.status.busy":"2024-01-29T20:02:03.003097Z","iopub.execute_input":"2024-01-29T20:02:03.003405Z","iopub.status.idle":"2024-01-29T20:02:20.122303Z","shell.execute_reply.started":"2024-01-29T20:02:03.003373Z","shell.execute_reply":"2024-01-29T20:02:20.120972Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Collecting bitsandbytes\n  Obtaining dependency information for bitsandbytes from https://files.pythonhosted.org/packages/9b/63/489ef9cd7a33c1f08f1b2be51d1b511883c5e34591aaa9873b30021cd679/bitsandbytes-0.42.0-py3-none-any.whl.metadata\n  Downloading bitsandbytes-0.42.0-py3-none-any.whl.metadata (9.9 kB)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.11.4)\nRequirement already satisfied: numpy<1.28.0,>=1.21.6 in /opt/conda/lib/python3.10/site-packages (from scipy->bitsandbytes) (1.24.3)\nDownloading bitsandbytes-0.42.0-py3-none-any.whl (105.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.42.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport torch\nfrom datasets import load_dataset\nfrom transformers import (\n    AutoModelForCausalLM,\n    LlamaForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    HfArgumentParser,\n    TrainingArguments,\n    pipeline,\n    logging,\n    DataCollatorForLanguageModeling\n)\nfrom peft import LoraConfig, PeftModel\nfrom trl import SFTTrainer, DataCollatorForCompletionOnlyLM\n\nfrom huggingface_hub import login","metadata":{"execution":{"iopub.status.busy":"2024-01-29T20:02:20.124078Z","iopub.execute_input":"2024-01-29T20:02:20.124480Z","iopub.status.idle":"2024-01-29T20:02:40.721576Z","shell.execute_reply.started":"2024-01-29T20:02:20.124436Z","shell.execute_reply":"2024-01-29T20:02:40.720197Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"sample_frac=0.2\nsplit_frac=0.2\ndata = pd.read_csv(\"/kaggle/input/fresult/result.csv\")\ndata = data.sample(frac=sample_frac)","metadata":{"execution":{"iopub.status.busy":"2024-01-29T20:02:40.723607Z","iopub.execute_input":"2024-01-29T20:02:40.724560Z","iopub.status.idle":"2024-01-29T20:02:44.786958Z","shell.execute_reply.started":"2024-01-29T20:02:40.724474Z","shell.execute_reply":"2024-01-29T20:02:44.786073Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"data['text'] = \"### question: \" + data['Question'] + \"### answer: \" + data['Answer']\ndata.head(3)","metadata":{"execution":{"iopub.status.busy":"2024-01-29T20:02:44.788662Z","iopub.execute_input":"2024-01-29T20:02:44.788994Z","iopub.status.idle":"2024-01-29T20:02:44.812660Z","shell.execute_reply.started":"2024-01-29T20:02:44.788967Z","shell.execute_reply":"2024-01-29T20:02:44.811740Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                                                 Context  \\\n18688                                                NaN   \n22889   عملکرد مناسبی را از این مدل CPUها انتظار داشت...   \n9960                                                 NaN   \n\n                                                Question  \\\n18688  چه قابلیتی را تراشه LA3-P در لنوو لیجن 9i فراه...   \n22889                 فرکانس مرجع این پردازنده چقدر است؟   \n9960   هنگامی که یک شخص به زمین بیفتد، چه اتفاقی میافتد؟   \n\n                                                  Answer  \\\n18688  تراشه LA3-P فراهم کننده قابلیت Lighting Audio ...   \n22889                                       ۳.۸ گیگاهرتز   \n9960   یک میکروفون درون Nobi درباره وضعیت از شخص سوال...   \n\n                                                    text  \n18688  ### question: چه قابلیتی را تراشه LA3-P در لنو...  \n22889  ### question: فرکانس مرجع این پردازنده چقدر اس...  \n9960   ### question: هنگامی که یک شخص به زمین بیفتد، ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Context</th>\n      <th>Question</th>\n      <th>Answer</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>18688</th>\n      <td>NaN</td>\n      <td>چه قابلیتی را تراشه LA3-P در لنوو لیجن 9i فراه...</td>\n      <td>تراشه LA3-P فراهم کننده قابلیت Lighting Audio ...</td>\n      <td>### question: چه قابلیتی را تراشه LA3-P در لنو...</td>\n    </tr>\n    <tr>\n      <th>22889</th>\n      <td>عملکرد مناسبی را از این مدل CPUها انتظار داشت...</td>\n      <td>فرکانس مرجع این پردازنده چقدر است؟</td>\n      <td>۳.۸ گیگاهرتز</td>\n      <td>### question: فرکانس مرجع این پردازنده چقدر اس...</td>\n    </tr>\n    <tr>\n      <th>9960</th>\n      <td>NaN</td>\n      <td>هنگامی که یک شخص به زمین بیفتد، چه اتفاقی میافتد؟</td>\n      <td>یک میکروفون درون Nobi درباره وضعیت از شخص سوال...</td>\n      <td>### question: هنگامی که یک شخص به زمین بیفتد، ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Split the dataframe into training and testing sets\ntrain, test = train_test_split(data, test_size=split_frac, random_state=42)\n\ntrain.to_csv(train_path, index=False)\ntest.to_csv(test_path, index=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-29T20:02:44.813932Z","iopub.execute_input":"2024-01-29T20:02:44.814246Z","iopub.status.idle":"2024-01-29T20:02:45.941212Z","shell.execute_reply.started":"2024-01-29T20:02:44.814220Z","shell.execute_reply":"2024-01-29T20:02:45.940253Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"login(token = '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')\n\n\n\ndataset = load_dataset(\"csv\", data_files={'train': train_path,\n                                          'validation': test_path})\n","metadata":{"execution":{"iopub.status.busy":"2024-01-29T20:02:45.945769Z","iopub.execute_input":"2024-01-29T20:02:45.946145Z","iopub.status.idle":"2024-01-29T20:02:47.222826Z","shell.execute_reply.started":"2024-01-29T20:02:45.946115Z","shell.execute_reply":"2024-01-29T20:02:47.221775Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\nToken is valid (permission: read).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31e86cc46b234c20ba92bec6a2546284"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a28528bfdb042ceaca9265815a30133"}},"metadata":{}}]},{"cell_type":"code","source":"# The model that you want to train from the Hugging Face hub\n# model_name = \"mostafaamiri/persian_llama_7b\"\nmodel_name = \"MaralGPT/Maral-7B-alpha-1\"\n\n# The instruction dataset to use\ndataset_name = \"mlabonne/guanaco-llama2-1k\"\n\n# Fine-tuned model name\nnew_model = \"persian-llama-2-7b-tech\"\n\n################################################################################\n# QLoRA parameters\n################################################################################\n\n# LoRA attention dimension\nlora_r = 16\n\n# Alpha parameter for LoRA scaling\nlora_alpha = 32\n\n# Dropout probability for LoRA layers\nlora_dropout = 0.05\n\n################################################################################\n# bitsandbytes parameters\n################################################################################\n\n# Activate 4-bit precision base model loading\nuse_4bit = True\n\n# Compute dtype for 4-bit base models\nbnb_4bit_compute_dtype = \"float16\"\n\n# Quantization type (fp4 or nf4)\nbnb_4bit_quant_type = \"nf4\"\n\n# Activate nested quantization for 4-bit base models (double quantization)\nuse_nested_quant = False\n\n################################################################################\n# TrainingArguments parameters\n################################################################################\n\n# Output directory where the model predictions and checkpoints will be stored\nhf_output_dir = os.path.join(output_dir, \"train_outputs\")\n\n# Number of training epochs\nnum_train_epochs = 5\n\n# Enable fp16/bf16 training (set bf16 to True with an A100)\nfp16 = False\nbf16 = False\n\n# Batch size per GPU for training\nper_device_train_batch_size = 1\n\n# Batch size per GPU for evaluation\nper_device_eval_batch_size = 1\n\n# Number of update steps to accumulate the gradients for\ngradient_accumulation_steps = 1\n\n# Enable gradient checkpointing\ngradient_checkpointing = True\n\n# Maximum gradient normal (gradient clipping)\nmax_grad_norm = 0.3\n\n# Initial learning rate (AdamW optimizer)\nlearning_rate = 8e-5\n\n# Weight decay to apply to all layers except bias/LayerNorm weights\nweight_decay = 0.001\n\n# Optimizer to use\noptim = \"paged_adamw_32bit\"\n\n# Learning rate schedule\nlr_scheduler_type = \"cosine\"\n\n# Number of training steps (overrides num_train_epochs)\nmax_steps = -1\n\n# Ratio of steps for a linear warmup (from 0 to learning rate)\nwarmup_ratio = 0.03\n\n# Group sequences into batches with same length\n# Saves memory and speeds up training considerably\ngroup_by_length = True\n\n# Save checkpoint every X updates steps\nsave_steps = 1000\n\n# Log every X updates steps\nlogging_steps = 200\n\n################################################################################\n# SFT parameters\n################################################################################\n\n# Maximum sequence length to use\nmax_seq_length = None\n\n# Pack multiple short examples in the same input sequence to increase efficiency\npacking = False\n\n# Load the entire model on the GPU 0\ndevice_map = {\"\": 0}","metadata":{"execution":{"iopub.status.busy":"2024-01-29T20:02:47.224253Z","iopub.execute_input":"2024-01-29T20:02:47.224584Z","iopub.status.idle":"2024-01-29T20:02:47.234953Z","shell.execute_reply.started":"2024-01-29T20:02:47.224556Z","shell.execute_reply":"2024-01-29T20:02:47.233884Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# Model, Configuration, and Tokenizer","metadata":{}},{"cell_type":"code","source":"# Load dataset (you can process it here)\n# dataset = load_dataset(dataset_name, split=\"train\")\n\n# Load tokenizer and model with QLoRA configuration\ncompute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=use_4bit,\n    bnb_4bit_quant_type=bnb_4bit_quant_type,\n    bnb_4bit_compute_dtype=compute_dtype,\n    bnb_4bit_use_double_quant=use_nested_quant,\n)\n\n# Check GPU compatibility with bfloat16\nif compute_dtype == torch.float16 and use_4bit:\n    major, _ = torch.cuda.get_device_capability()\n    if major >= 8:\n        print(\"=\" * 80)\n        print(\"Your GPU supports bfloat16: accelerate training with bf16=True\")\n        print(\"=\" * 80)\n\n# Load base model\n# model = AutoModelForCausalLM.from_pretrained(\n#     model_name,\n#     torch_dtype=torch.bfloat16,\n#     load_in_4bit=True,\n#     quantization_config=bnb_config,\n#     device_map=device_map\n# )\n\nmodel = LlamaForCausalLM.from_pretrained(\n    \"mostafaamiri/base_7B\",\n    load_in_8bit=True,\n    torch_dtype=torch.bfloat16,\n    low_cpu_mem_usage=True,\n    device_map=\"auto\",\n    )\n\nmodel.config.use_cache = False\nmodel.config.pretraining_tp = 1\n\n# Load LLaMA tokenizer\ntokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\ntokenizer.pad_token = tokenizer.eos_token\ntokenizer.padding_side = \"right\" # Fix weird overflow issue with fp16 training\n\n# Load LoRA configuration\npeft_config = LoraConfig(\n    lora_alpha=lora_alpha,\n    lora_dropout=lora_dropout,\n    r=lora_r,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-29T20:02:47.236174Z","iopub.execute_input":"2024-01-29T20:02:47.236470Z","iopub.status.idle":"2024-01-29T20:04:22.307404Z","shell.execute_reply.started":"2024-01-29T20:02:47.236444Z","shell.execute_reply":"2024-01-29T20:04:22.306474Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26afc03f160542d7ae7c85ab65f00669"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6963aa43c1e4a6fa6785fe5192e51e6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3070177343b34691941483a66358089a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9edb7c9156344d5969d1e0a4ae15f1f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ebe7ea2c4bae455e93b3922da455ab09"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0876f37328214257990005fe3c9e5d7d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb2396c5943b460983a0f78c4fee61bd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/967 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"610265dda817409baeaf85d7be2b4fa0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1527047673df49fd8974106acac95f33"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d07484a168c40b892c3033e00abe120"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3427c80431244d06a84f60bf1cdd9aef"}},"metadata":{}}]},{"cell_type":"markdown","source":"# Training Args, Data Collator, and SFTTrainer","metadata":{}},{"cell_type":"code","source":"# Set training parameters\ntraining_arguments = TrainingArguments(\n    output_dir=hf_output_dir,\n    overwrite_output_dir=True,\n    num_train_epochs=num_train_epochs,\n    per_device_train_batch_size=per_device_train_batch_size,\n    gradient_accumulation_steps=gradient_accumulation_steps,\n    optim=optim,\n    save_steps=save_steps,\n    logging_steps=logging_steps,\n    save_total_limit=2,\n    learning_rate=learning_rate,\n    weight_decay=weight_decay,\n    fp16=fp16,\n    bf16=bf16,\n    max_grad_norm=max_grad_norm,\n    max_steps=max_steps,\n    warmup_ratio=warmup_ratio,\n    group_by_length=group_by_length,\n    lr_scheduler_type=lr_scheduler_type,\n    report_to=\"tensorboard\"\n)\ntokenizer.padding_side = 'right'\n# instruction_template = \"### question:\"\n# response_template = \"### answer:\"\n# collator = DataCollatorForCompletionOnlyLM(instruction_template=instruction_template, response_template=response_template, tokenizer=tokenizer, mlm=False)\ncollator = DataCollatorForLanguageModeling(\n    tokenizer=tokenizer,\n    mlm=False\n)\n\n# Set supervised fine-tuning parameters\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=dataset['train'],\n    eval_dataset=dataset['validation'],\n    \n    peft_config=peft_config,\n    dataset_text_field=\"text\",\n    max_seq_length=max_seq_length,\n#     max_length=1024,\n    tokenizer=tokenizer,\n    args=training_arguments,\n    packing=packing,\n    data_collator=collator\n)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-29T20:12:33.603799Z","iopub.execute_input":"2024-01-29T20:12:33.604645Z","iopub.status.idle":"2024-01-29T20:12:34.759370Z","shell.execute_reply.started":"2024-01-29T20:12:33.604611Z","shell.execute_reply":"2024-01-29T20:12:34.758401Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:223: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/4960 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1535418ec66048c49583a365dad9f94a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1240 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1abfaf45cf447f8892fa3ba7ff6a0ec"}},"metadata":{}}]},{"cell_type":"markdown","source":"# Train and Save","metadata":{}},{"cell_type":"code","source":"# Train model\ntrainer.train()\n\n# Save trained model\ntrainer.model.save_pretrained(new_model_path)","metadata":{"execution":{"iopub.status.busy":"2024-01-29T20:12:40.277060Z","iopub.execute_input":"2024-01-29T20:12:40.277409Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='9902' max='24800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 9902/24800 3:06:09 < 4:40:08, 0.89 it/s, Epoch 2.00/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>200</td>\n      <td>6.383200</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>3.091600</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>2.694500</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>2.357600</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>2.206300</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>2.077000</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>1.982800</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>1.881900</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>1.775800</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>1.802200</td>\n    </tr>\n    <tr>\n      <td>2200</td>\n      <td>1.705300</td>\n    </tr>\n    <tr>\n      <td>2400</td>\n      <td>1.687400</td>\n    </tr>\n    <tr>\n      <td>2600</td>\n      <td>1.662200</td>\n    </tr>\n    <tr>\n      <td>2800</td>\n      <td>1.602800</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>1.574400</td>\n    </tr>\n    <tr>\n      <td>3200</td>\n      <td>1.544300</td>\n    </tr>\n    <tr>\n      <td>3400</td>\n      <td>1.489500</td>\n    </tr>\n    <tr>\n      <td>3600</td>\n      <td>1.528700</td>\n    </tr>\n    <tr>\n      <td>3800</td>\n      <td>1.519400</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>1.472300</td>\n    </tr>\n    <tr>\n      <td>4200</td>\n      <td>1.423100</td>\n    </tr>\n    <tr>\n      <td>4400</td>\n      <td>1.416000</td>\n    </tr>\n    <tr>\n      <td>4600</td>\n      <td>1.473300</td>\n    </tr>\n    <tr>\n      <td>4800</td>\n      <td>1.382900</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>1.377900</td>\n    </tr>\n    <tr>\n      <td>5200</td>\n      <td>1.302600</td>\n    </tr>\n    <tr>\n      <td>5400</td>\n      <td>1.267600</td>\n    </tr>\n    <tr>\n      <td>5600</td>\n      <td>1.290700</td>\n    </tr>\n    <tr>\n      <td>5800</td>\n      <td>1.343700</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>1.291800</td>\n    </tr>\n    <tr>\n      <td>6200</td>\n      <td>1.281500</td>\n    </tr>\n    <tr>\n      <td>6400</td>\n      <td>1.255700</td>\n    </tr>\n    <tr>\n      <td>6600</td>\n      <td>1.304900</td>\n    </tr>\n    <tr>\n      <td>6800</td>\n      <td>1.262100</td>\n    </tr>\n    <tr>\n      <td>7000</td>\n      <td>1.305000</td>\n    </tr>\n    <tr>\n      <td>7200</td>\n      <td>1.297300</td>\n    </tr>\n    <tr>\n      <td>7400</td>\n      <td>1.240300</td>\n    </tr>\n    <tr>\n      <td>7600</td>\n      <td>1.296500</td>\n    </tr>\n    <tr>\n      <td>7800</td>\n      <td>1.251100</td>\n    </tr>\n    <tr>\n      <td>8000</td>\n      <td>1.251400</td>\n    </tr>\n    <tr>\n      <td>8200</td>\n      <td>1.208200</td>\n    </tr>\n    <tr>\n      <td>8400</td>\n      <td>1.194400</td>\n    </tr>\n    <tr>\n      <td>8600</td>\n      <td>1.205500</td>\n    </tr>\n    <tr>\n      <td>8800</td>\n      <td>1.189800</td>\n    </tr>\n    <tr>\n      <td>9000</td>\n      <td>1.178800</td>\n    </tr>\n    <tr>\n      <td>9200</td>\n      <td>1.210000</td>\n    </tr>\n    <tr>\n      <td>9400</td>\n      <td>1.191900</td>\n    </tr>\n    <tr>\n      <td>9600</td>\n      <td>1.217100</td>\n    </tr>\n    <tr>\n      <td>9800</td>\n      <td>1.197400</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# training and validation curves","metadata":{}},{"cell_type":"code","source":"plots_dir = os.path.join(output_dir, \"plots\")\nos.makedirs(plots_dir, exist_ok=True)\nos.makedirs(hf_output_dir, exist_ok=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot as plt\n\n\n# Plot the training and validation loss curves\ntrain_loss = trainer.state.log_history[\"loss\"]\nval_loss = trainer.state.log_history[\"eval_loss\"]\nplt.plot(train_loss, label=\"Training Loss\")\nplt.plot(val_loss, label=\"Validation Loss\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.title(\"Training and Validation Loss Curves\")\nplt.legend()\nplt.show()\nplt.savefig(os.path.join(plots_dir, \"TrainAndValidCurves.png\"), format='png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Learning rate schedule curve","metadata":{}},{"cell_type":"code","source":"# Plot the learning rate schedule\nlearning_rate = trainer.state.log_history[\"learning_rate\"]\nplt.plot(learning_rate)\nplt.xlabel(\"Step\")\nplt.ylabel(\"Learning Rate\")\nplt.title(\"Learning Rate Schedule\")\nplt.show()\nplt.savefig(os.path.join(plots_dir, \"lrScheduleCurves.png\"), format='png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}